<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Why Quantisation Matters for LLMs | ross.</title>
<meta name="keywords" content="">
<meta name="description" content="Large language models (LLMs) are powerful but expensive to run. A model with 7 billion parameters stored in FP32 requires around 28 GB of memory just for weights (7e9 × 4 bytes). For larger models such as LLaMA-70B, this rises into the hundreds of gigabytes. These numbers explain why LLMs usually run in datacentres on specialised GPUs with high memory bandwidth.
If we want to deploy models on consumer hardware or edge devices, these requirements are too high. Laptops and phones rarely have more than a few gigabytes available for AI tasks, and embedded systems often have less. Quantisation is one of the main ways to close this gap.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/large-language-model-quantization---part-1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b489a6d73b9d5f542e10296b5fbfe24c07a73618c7ca7efba908fadedc6200f9.css" integrity="sha256-tImm1zudX1QuEClrX7/iTAenNhjHyn77qQj63txiAPk=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/large-language-model-quantization---part-1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="ross. (Alt + H)">ross.</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Why Quantisation Matters for LLMs
    </h1>
    <div class="post-meta"><span title='2025-09-24 10:00:00 +0100 BST'>September 24, 2025</span>&nbsp;·&nbsp;2 min

</div>
  </header> 
  <div class="post-content"><p>Large language models (LLMs) are powerful but expensive to run. A model with 7 billion parameters stored in FP32 requires around 28 GB of memory just for weights (7e9 × 4 bytes). For larger models such as LLaMA-70B, this rises into the hundreds of gigabytes. These numbers explain why LLMs usually run in datacentres on specialised GPUs with high memory bandwidth.</p>
<p>If we want to deploy models on consumer hardware or edge devices, these requirements are too high. Laptops and phones rarely have more than a few gigabytes available for AI tasks, and embedded systems often have less. <strong>Quantisation is one of the main ways to close this gap.</strong></p>
<hr>
<h2 id="what-quantisation-does">What quantisation does<a hidden class="anchor" aria-hidden="true" href="#what-quantisation-does">#</a></h2>
<p>Quantisation reduces the precision of numbers stored in the model. Instead of FP32, we use FP16, INT8, or INT4. This has three direct effects:</p>
<ol>
<li>
<p><strong>Smaller memory footprint</strong></p>
<ul>
<li>A 7B model at FP16 is ~14 GB.</li>
<li>At INT8, it’s ~7 GB.</li>
<li>At INT4, it drops to ~3.5 GB.</li>
</ul>
<p>These differences are the difference between “cannot load” and “runs on a single GPU or CPU”.</p>
</li>
<li>
<p><strong>Faster inference</strong><br>
Modern hardware executes low-precision arithmetic faster and moves less data through memory channels. INT8 or INT4 kernels can achieve higher throughput.</p>
</li>
<li>
<p><strong>Lower power use</strong><br>
Memory access is expensive in terms of energy. With fewer bytes to move, battery life on mobile or embedded devices improves.</p>
</li>
</ol>
<hr>
<h2 id="why-edge-deployment-makes-this-important">Why edge deployment makes this important<a hidden class="anchor" aria-hidden="true" href="#why-edge-deployment-makes-this-important">#</a></h2>
<p>For cloud providers, the trade-off is between efficiency and accuracy. For edge devices, it’s often <strong>feasibility</strong>:</p>
<ul>
<li><strong>Mobile apps</strong>: chat assistants, transcription, or summarisation directly on a phone.</li>
<li><strong>IoT devices</strong>: local reasoning without sending data to the cloud.</li>
<li><strong>Privacy-sensitive settings</strong>: healthcare or finance, where keeping data local avoids exposure.</li>
</ul>
<p>Quantisation makes these scenarios realistic.</p>
<hr>
<h2 id="the-cost-accuracy-trade-offs">The cost: accuracy trade-offs<a hidden class="anchor" aria-hidden="true" href="#the-cost-accuracy-trade-offs">#</a></h2>
<p>Reducing precision introduces quantisation error. If a weight distribution has many outliers, compressing it to 4 bits can distort the range, leading to degraded fluency or higher perplexity. Accuracy loss depends on the scheme used and the model architecture.</p>
<p>Some approaches leave sensitive layers in higher precision (embeddings, normalisation layers) while quantising others. Others combine quantisation with retraining so the model learns to be robust.</p>
<hr>
<h2 id="outlook">Outlook<a hidden class="anchor" aria-hidden="true" href="#outlook">#</a></h2>
<p>Quantisation is not the only approach — pruning and distillation are also active research areas — but it is the most direct route to shrinking a model while keeping the same architecture. In the next post, I’ll break down how quantisation works in practice, the different schemes used, and the tools available today.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">ross.</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
